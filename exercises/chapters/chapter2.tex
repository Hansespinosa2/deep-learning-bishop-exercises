\section{Probabilities}

\subsection*{Exercise 2.1}
Bayes rule
\begin{gather}
  P[C=1|T=1] = \frac{P[T=1|C=1]*P[C=1]}{P[T=1|C=1]*P[C=1] + P[T=1|C=0]*P[C=0]} \\
  P[C=1|T=1]= \frac{0.90*0.001}{0.90*0.001 + 0.03*0.999} = 0.0292
\end{gather}

Given that the test result was positive, there is a 2.92\% chance that you have cancer.

\subsection{Exercise 2.2}
Not attempted

\subsection*{Exercise 2.3}
\begin{gather}
  p(\mathbf{y}) = \int p_\mathbf{u},_\mathbf{v}(\mathbf{u},\mathbf{y}-\mathbf{u})d\mathbf{u} \\
  = \int p_\mathbf{u}(\mathbf{u})p_\mathbf{v}(\mathbf{y} - \mathbf{u})d\mathbf{u}
\end{gather}

\subsection{Exercise 2.4}
Not attempted

\subsection*{Exercise 2.5}
Exponential:
\begin{equation}
  p(x|\lambda) = \lambda e^{-\lambda x}
\end{equation}

Laplace: 
\begin{equation}
  p(x|\mu,\gamma) = \frac{1}{2\gamma} e^{-\frac{|x-\mu|}{\gamma}}
\end{equation}

Verifying that the exponential distribution is normalized: 

\begin{gather}
  p(x|\lambda) = \lambda e^{-\lambda x} \\
  \int_{0}^{\infty} \lambda e^{-\lambda x} = -e^{-\lambda x} \Big |_0^\infty = \frac{1}{e^\infty} + \frac{1}{e^0} \\
 = 1
\end{gather}

Verifying the laplace distribution:

\begin{equation}
  p(x|\mu,\gamma) = \frac{1}{2\gamma} e^{-\frac{|x-\mu|}{\gamma}} \\
\end{equation}


\begin{equation}
  \begin{cases}
    \frac{1}{2\gamma} e^{-\frac{x-\mu}{\gamma}} & \text{if } x \geq \mu \\
    \frac{1}{2\gamma} e^{-\frac{-x+\mu}{\gamma}} & \text{if } x < \mu
  \end{cases}
\end{equation}

\begin{gather}
  \int_{\mu}^{\infty}\frac{1}{2\gamma} e^{-\frac{x-\mu}{\gamma}} = \frac{1}{2} e^{-\frac{x-\mu}{\gamma}} \Big |_\mu^\infty = -\frac{1}{2}(e^{-\infty} - e^0) \\
  = \frac{1}{2} \\
  \int_{-\infty}^{\mu}\frac{1}{2\gamma} e^{-\frac{-x+\mu}{\gamma}} = \frac{1}{2} e^{-\frac{-x+\mu}{\gamma}} \Big |_{-\infty}^\mu = \frac{1}{2}(e^{0} - e^{-\infty}) \\
  = \frac{1}{2} \\ 
  \frac{1}{2} + \frac{1}{2} = 1
\end{gather}


\subsection{Exercise 2.6}
Not attempted

\subsection{Exercise 2.7}

\begin{gather}
  P(x|D) = \frac{1}{N}\sum_{n=1}^N \delta(x-x_n) \\
  E[f] = \int p(x)f(x)dx \\
  \text{Substituting:} \\
  E[f] = \int \frac{1}{N}\sum_{n=1}^N \delta(x-x_n) f(x) dx \\
  E[f] =  \frac{1}{N}\sum_{n=1}^N \int_{x_n- \varepsilon}^{x_n + \varepsilon} \delta(x-x_n) f(x) dx \\
  E[f] =  \frac{1}{N}\sum_{n=1}^N f(x_n) \int_{x_n- \varepsilon}^{x_n + \varepsilon} \delta(x-x_n) dx \\
  E[f] =  \frac{1}{N}\sum_{n=1}^N f(x_n)
\end{gather}

\subsection{Exercise 2.8}
Not attempted

\subsection{Exercise 2.9}

\begin{equation}
  cov[X,y] = E_{x,y}[xy] - E[x]E[y] \\
\end{equation}

If x and y are independent, the joint distribution is equal to the product of the marginals. $p(x,y) = p(x)p(y)$. If $E_{x,y}[xy] = E[x]E[y]$, then the covariance will be zero.

\subsection{Exercise 2.10}
Not attempted

\subsection{Exercise 2.11}
Proving $E[x] = E_y[E_x[x|y]]$:
\begin{gather}
  E_x[x|y] = \int p(x|y)xdx \\
  \text{Substituting:} \\
  E[x] = E_y[\int p(x|y)xdx] \\
  E[x] = \int E_y[p(x|y)]xdx \\
  E[x] = \int \int p(x|y)xp(y) dxdy \\
  E[x] = \int \int \frac{p(x,y)}{p(y)}xp(y) dxdy \\
  E[x] = \int \int p(x,y)x dxdy \\
  E[x] = E[x]
\end{gather}


\subsection{Exercise 2.12}
Not attempted

\subsection{Exercise 2.13}

\begin{gather}
  E[x] = \int_{-\infty}^{\infty} x \frac{1}{\sqrt{2\pi \sigma^2}} e^{\frac{1}{2\sigma^2}(x-\mu)^2}dx \\
  \text{Change of variables } z = \frac{x-\mu}{\sigma}, \sigma dz = dx \\
  E[x] = \int_{-\infty}^{\infty}  \sigma \frac{\sigma z + \mu}{\sqrt{2\pi \sigma^2}} e^{\frac{1}{2}z^2}dz \\
  E[x] = \frac{\sigma}{\sqrt{2\pi}} \int_{-\infty}^{\infty}   z e^{\frac{1}{2}z^2}  + \frac{\mu}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{\frac{1}{2}z^2} \\
  E[x] = \frac{\sigma}{\sqrt{2\pi}} * 0 +  \frac{\mu}{\sqrt{2\pi}} * \sqrt{2\pi} \\
  E[x] = \mu
\end{gather}

\subsection{Exercise 2.14}
Not attempted
\subsection{Exercise 2.15}
Solving for $\mu_{ml}$: 
\begin{gather}
  \log p(x|\mu,\sigma^2) = \frac{-1}{2\sigma^2}\sum_{n=1}^{N}(x_n - \mu)^2 - \frac{N}{2}\log \sigma^2 - \frac{N}{2}\log 2\pi \\
  \frac{d}{d\mu} log p(x|\mu,\sigma^2) = \frac{1}{2\sigma^2}\sum_{n=1}^{N}2(x_n - \mu) \\
  0 = \frac{1}{\sigma^2}\sum_{n=1}^{N}(x_n - \mu) \\ 
  0 = \sum_{n=1}^{N}x_n - \sum_{n=1}^{N}\mu \\
  N\mu = \sum_{n=1}^{N}x_n \\ 
  \mu_{ml} = \frac{1}{n} \sum_{n=1}^{N}x_n
\end{gather}

Solving for $\sigma_{ml}$:

\begin{gather}
  \log p(x|\mu,\sigma^2) = \frac{-1}{2\sigma^2}\sum_{n=1}^{N}(x_n - \mu)^2 - \frac{N}{2}\log \sigma^2 - \frac{N}{2}\log 2\pi \\
  \frac{d}{d\sigma^2} log p(x|\mu,\sigma^2) = \frac{1}{2\sigma^4}\sum_{n=1}^{N}(x_n - \mu)^2 - \frac{N}{2\sigma^2} \\
  \frac{N}{2\sigma^2} = \frac{1}{2\sigma^4}\sum_{n=1}^{N}(x_n - \mu)^2 \\
  \sigma_{ml}^2 =  \frac{1}{N}\sum_{n=1}^{N}(x_n - \mu_{ml})^2
\end{gather}

\subsection{Exercise 2.16}
not attempted

\subsection{Exercise 2.17}
Finding expectation of $\hat{\sigma}^2$

\begin{gather}
  E[\hat{\sigma}^2] = E[\frac{1}{N}\sum_{n=1}^{N}(x_n - \mu)^2] \\
  = \frac{1}{N}\sum_{n=1}^{N}E[x_n^2 - 2x_n\mu + \mu^2] \\
  = \frac{1}{N}\sum_{n=1}^{N}E[x_n^2] - E[2x_n\mu] +E[\mu^2] \\
  = \frac{1}{N}\sum_{n=1}^{N}E[x_n^2] - 2E[x_n]E[x_n] +E[\mu^2] \\
  = \frac{1}{N}\sum_{n=1}^{N}E[x_n^2] - E[x_n]^2 \\
  = \frac{1}{N}\sum_{n=1}^{N} \mu^2 + \sigma^2 - \mu^2 \\
  = \sigma^2
\end{gather}

\subsection{Exercise 2.18}
Not attempted

\subsection{Exercise 2.19}
\begin{center}
  \setlength{\unitlength}{1cm}
  \begin{picture}(14,6)
  
      % Axes for q(x)
      \put(0,0.5){\vector(1,0){4}} % x-axis
      \put(0,0.5){\vector(0,1){4}} % y-axis
      \put(4,0){\makebox(0,0)[t]{$x$}}
      \put(0,4.5){\makebox(0,0)[r]{$q(x)$}}
  
      % Axes for p(y)
      \put(10,0.5){\vector(1,0){4}} % y-axis
      \put(10,0.5){\vector(0,1){4}} % p-axis
      \put(14,0){\makebox(0,0)[t]{$y$}}
      \put(10,4.5){\makebox(0,0)[r]{$p(y)$}}
  
      % Density function q(x)
      \put(0,0.5){\line(1,1){3}}   % Linear increasing
      \put(3,3.5){\circle*{0.1}}   % Point at (3,3.5)
      \put(2,3){\makebox(0,0)[r]{$q(x)$}}
  
      % Density function p(y)
      \put(10,0.5){\line(1,1){3}}  % Linear increasing
      \put(13,3.5){\circle*{0.1}}  % Point at (13,3.5)
      \put(12,3){\makebox(0,0)[r]{$p(y)$}}
  
      % Transformation arrow
      \put(4,2){\vector(1,0){6}}
      \put(7,2.2){\makebox(0,0)[b]{$y = f(x)$}}
  
  \end{picture}
  \end{center}

\subsection{Exercise 2.20}
Not attempted

\subsection{Exercise 2.21}
Showing $h(p^2) = 2h(p)$:
\begin{gather}
  h(p) = h(p(x_1)) + h(p(x_2)) + \dots + h(p(x_n)) \\
  h(p^2) = h(x_1^2) + h(x_2^2) + \dots + h(x_n^2) \\
  \because h(x) = -\log_2 p(x), \\
  h(p^2) = 2h(x_1) + 2h(x_2) + \dots + 2h(x_n) \\
  h(p^2) = 2h(p)
\end{gather}

This can be applied to any exponent which inclues any choice of $n$ integer or $\frac{n}{m}$ positive rational number.
\begin{gather}
  h(p^x) = xh(p) \text{ }\forall\text{ } Q^+ \\
  \therefore \\
  h(p) \propto ln p
\end{gather}


\subsection{Exercise 2.22}
Not attempted

\subsection{Exercise 2.23}
Not attempted

\subsection{Exercise 2.24}
Not attempted

\subsection{Exercise 2.25}
Not attempted

\subsection{Exercise 2.26}
Not attempted

\subsection{Exercise 2.27}
Not attempted

\subsection{Exercise 2.28}
Not attempted

\subsection{Exercise 2.29}
Not attempted

\subsection{Exercise 2.30}
Not attempted

\subsection{Exercise 2.31}
Not attempted

\subsection{Exercise 2.32}
Not attempted

\subsection{Exercise 2.33}
Not attempted

\subsection{Exercise 2.34}
Not attempted

\subsection{Exercise 2.35}
Not attempted

\subsection{Exercise 2.36}
Not attempted

\subsection{Exercise 2.37}
Not attempted

\subsection{Exercise 2.38}
Not attempted

\subsection{Exercise 2.39}
Not attempted

\subsection{Exercise 2.40}
Not attempted

\subsection{Exercise 2.41}
Not attempted
